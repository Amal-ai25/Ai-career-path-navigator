{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "B471i-6FeD8q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Xif3H3aoYX",
        "outputId": "d97fb3f6-d9eb-4ea0-94df-51525d3dbd88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['le_campus.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# Load your expanded dataset\n",
        "df = pd.read_csv('LU_Major_Recommendation_Dataset_New.csv')\n",
        "\n",
        "# Convert string lists to actual lists\n",
        "def parse_string_list(x):\n",
        "    if isinstance(x, str):\n",
        "        # Clean and split the string\n",
        "        return [item.strip() for item in re.split(r',|;', x) if item.strip()]\n",
        "    return x\n",
        "\n",
        "df['Skills'] = df['Skills'].apply(parse_string_list)\n",
        "df['Courses and Certificates'] = df['Courses and Certificates'].apply(parse_string_list)\n",
        "\n",
        "# Convert RIASEC to 0/1\n",
        "riasec_columns = ['R', 'I', 'A', 'S', 'E', 'C']\n",
        "for col in riasec_columns:\n",
        "    df[col] = df[col].astype(int)\n",
        "\n",
        "# Separate passion and goals (and drop goals as requested)\n",
        "def extract_passion(text):\n",
        "    if isinstance(text, str):\n",
        "        # Split by comma and take first part as passion\n",
        "        parts = text.split(',')\n",
        "        return parts[0].strip() if parts else text\n",
        "    return text\n",
        "\n",
        "df['Passion'] = df['Passion and Goals'].apply(extract_passion)\n",
        "df = df.drop('Passion and Goals', axis=1)\n",
        "\n",
        "# Create master lists for NLP matching\n",
        "all_skills = set()\n",
        "for skills in df['Skills']:\n",
        "    all_skills.update(skills)\n",
        "all_skills = list(all_skills)\n",
        "\n",
        "all_courses = set()\n",
        "for courses in df['Courses and Certificates']:\n",
        "    all_courses.update(courses)\n",
        "all_courses = list(all_courses)\n",
        "\n",
        "all_passions = set(df['Passion'])\n",
        "all_passions = list(all_passions)\n",
        "\n",
        "all_work_styles = set(df['Work Style'])\n",
        "all_work_styles = list(all_work_styles)\n",
        "\n",
        "# Save these master lists for later use in prediction\n",
        "import joblib\n",
        "joblib.dump(all_skills, 'master_skills.pkl')\n",
        "joblib.dump(all_courses, 'master_courses.pkl')\n",
        "joblib.dump(all_passions, 'master_passions.pkl')\n",
        "joblib.dump(all_work_styles, 'master_work_styles.pkl')\n",
        "\n",
        "# Prepare features for ML model\n",
        "# 1. RIASEC features (already 0/1)\n",
        "X_riasec = df[riasec_columns]\n",
        "\n",
        "# 2. Skills features (MultiLabelBinarizer)\n",
        "mlb_skills = MultiLabelBinarizer()\n",
        "X_skills = mlb_skills.fit_transform(df['Skills'])\n",
        "joblib.dump(mlb_skills, 'mlb_skills.pkl')\n",
        "\n",
        "# 3. Courses features (MultiLabelBinarizer)\n",
        "mlb_courses = MultiLabelBinarizer()\n",
        "X_courses = mlb_courses.fit_transform(df['Courses and Certificates'])\n",
        "joblib.dump(mlb_courses, 'mlb_courses.pkl')\n",
        "\n",
        "# 4. Work Style features (OneHotEncoder)\n",
        "ohe_work_style = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_work_style = ohe_work_style.fit_transform(df[['Work Style']])\n",
        "joblib.dump(ohe_work_style, 'ohe_work_style.pkl')\n",
        "\n",
        "# 5. Passion features (OneHotEncoder)\n",
        "ohe_passion = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_passion = ohe_passion.fit_transform(df[['Passion']])\n",
        "joblib.dump(ohe_passion, 'ohe_passion.pkl')\n",
        "\n",
        "# Combine all features\n",
        "X = np.hstack([X_riasec, X_skills, X_courses, X_work_style, X_passion])\n",
        "\n",
        "# Prepare target variables\n",
        "le_major = LabelEncoder()\n",
        "le_faculty = LabelEncoder()\n",
        "le_degree = LabelEncoder()\n",
        "le_campus = LabelEncoder()\n",
        "\n",
        "y_major = le_major.fit_transform(df['Program/Major'])\n",
        "y_faculty = le_faculty.fit_transform(df['Faculty'])\n",
        "y_degree = le_degree.fit_transform(df['Typical Degree'])\n",
        "y_campus = le_campus.fit_transform(df['Primary Campus'])\n",
        "\n",
        "y = np.column_stack((y_major, y_faculty, y_degree, y_campus))\n",
        "\n",
        "# Save label encoders\n",
        "joblib.dump(le_major, 'le_major.pkl')\n",
        "joblib.dump(le_faculty, 'le_faculty.pkl')\n",
        "joblib.dump(le_degree, 'le_degree.pkl')\n",
        "joblib.dump(le_campus, 'le_campus.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_user_text_input(user_input, master_list, threshold=70):\n",
        "    \"\"\"\n",
        "    Process user text input using fuzzy matching\n",
        "    \"\"\"\n",
        "    if not user_input or not isinstance(user_input, str):\n",
        "        return []\n",
        "\n",
        "    detected_items = []\n",
        "    # Try to match the whole input first\n",
        "    best_match, score = process.extractOne(user_input, master_list, scorer=fuzz.partial_ratio)\n",
        "    if score >= threshold:\n",
        "        detected_items.append(best_match)\n",
        "\n",
        "    # Also try to match individual words\n",
        "    words = re.findall(r'\\b\\w+\\b', user_input.lower())\n",
        "    for word in words:\n",
        "        if len(word) > 3:  # Only consider words longer than 3 characters\n",
        "            best_match, score = process.extractOne(word, master_list, scorer=fuzz.partial_ratio)\n",
        "            if score >= threshold:\n",
        "                detected_items.append(best_match)\n",
        "\n",
        "    return list(set(detected_items))  # Remove duplicates\n",
        "\n",
        "def prepare_user_input(user_data):\n",
        "    \"\"\"\n",
        "    Prepare user input for prediction\n",
        "    user_data should be a dictionary with:\n",
        "    - riasec: dict with R,I,A,S,E,C as keys and 0/1 as values\n",
        "    - skills_text: string of user skills\n",
        "    - courses_text: string of user courses\n",
        "    - work_style: string of selected work style\n",
        "    - passion_text: string of user passion\n",
        "    \"\"\"\n",
        "    # Load master lists\n",
        "    all_skills = joblib.load('master_skills.pkl')\n",
        "    all_courses = joblib.load('master_courses.pkl')\n",
        "    all_passions = joblib.load('master_passions.pkl')\n",
        "    all_work_styles = joblib.load('master_work_styles.pkl')\n",
        "\n",
        "    # Load encoders\n",
        "    mlb_skills = joblib.load('mlb_skills.pkl')\n",
        "    mlb_courses = joblib.load('mlb_courses.pkl')\n",
        "    ohe_work_style = joblib.load('ohe_work_style.pkl')\n",
        "    ohe_passion = joblib.load('ohe_passion.pkl')\n",
        "\n",
        "    # Process RIASEC\n",
        "    riasec_order = ['R', 'I', 'A', 'S', 'E', 'C']\n",
        "    X_riasec = np.array([[user_data['riasec'].get(col, 0) for col in riasec_order]])\n",
        "\n",
        "    # Process Skills with NLP\n",
        "    detected_skills = process_user_text_input(user_data['skills_text'], all_skills)\n",
        "    X_skills = mlb_skills.transform([detected_skills])\n",
        "\n",
        "    # Process Courses with NLP\n",
        "    detected_courses = process_user_text_input(user_data['courses_text'], all_courses)\n",
        "    X_courses = mlb_courses.transform([detected_courses])\n",
        "\n",
        "    # Process Work Style\n",
        "    # If user's work style isn't found, use the most common one\n",
        "    work_style = user_data['work_style']\n",
        "    if work_style not in all_work_styles:\n",
        "        work_style = all_work_styles[0]  # or use most common\n",
        "    X_work_style = ohe_work_style.transform([[work_style]])\n",
        "\n",
        "    # Process Passion with NLP\n",
        "    detected_passion = process_user_text_input(user_data['passion_text'], all_passions)\n",
        "    passion = detected_passion[0] if detected_passion else all_passions[0]\n",
        "    X_passion = ohe_passion.transform([[passion]])\n",
        "\n",
        "    # Combine all features\n",
        "    X_user = np.hstack([X_riasec, X_skills, X_courses, X_work_style, X_passion])\n",
        "\n",
        "    return X_user, {\n",
        "        'detected_skills': detected_skills,\n",
        "        'detected_courses': detected_courses,\n",
        "        'detected_passion': passion\n",
        "    }"
      ],
      "metadata": {
        "id": "P6xb5XMzSOrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y[:, 0]  # stratify by major\n",
        ")\n",
        "\n",
        "# Train a MultiOutput Classifier\n",
        "model = MultiOutputClassifier(RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    max_depth=10,\n",
        "    class_weight='balanced'\n",
        "))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "# Predictions\n",
        "\n",
        "\n",
        "\n",
        "# Bias vs Variance insight\n",
        "print(\"\\nIf Training Accuracy >> Test Accuracy → High Variance (overfitting)\")\n",
        "print(\"If Training Accuracy and Test Accuracy are both low → High Bias (underfitting)\")\n",
        "print(\"If both are high and close → Good Generalization\")\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "Y_train_pred = model.predict(X_train)\n",
        "Y_test_pred = model.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred) # This line is causing the error\n",
        "# print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Evaluate each target separately\n",
        "target_names = ['Major', 'Faculty', 'Degree', 'Campus']\n",
        "for i, name in enumerate(target_names):\n",
        "\n",
        "\n",
        "\n",
        "# Compute training and test accuracy\n",
        "  train_accuracy = accuracy_score(y_train[:, i], Y_train_pred[:, i])\n",
        "  test_accuracy = accuracy_score(y_test[:, i], Y_test_pred[:, i])\n",
        "\n",
        "\n",
        "  print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "  print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "  acc = accuracy_score(y_test[:, i], y_pred[:, i])\n",
        "  print(f\"{name} Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'major_recommendation_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfqSpuVdSXrW",
        "outputId": "9a32d2a1-e9f2-4768-e186-7280179fc207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "If Training Accuracy >> Test Accuracy → High Variance (overfitting)\n",
            "If Training Accuracy and Test Accuracy are both low → High Bias (underfitting)\n",
            "If both are high and close → Good Generalization\n",
            "Training Accuracy: 1.00\n",
            "Test Accuracy: 0.96\n",
            "Major Accuracy: 0.9569\n",
            "Training Accuracy: 0.99\n",
            "Test Accuracy: 0.97\n",
            "Faculty Accuracy: 0.9741\n",
            "Training Accuracy: 0.98\n",
            "Test Accuracy: 0.93\n",
            "Degree Accuracy: 0.9310\n",
            "Training Accuracy: 0.95\n",
            "Test Accuracy: 0.92\n",
            "Campus Accuracy: 0.9224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['major_recommendation_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#After we checked the training accuracy and testing accuracy we noticed that both bias and variance are both low and thats good there is no overfitting and no underfitting problems."
      ],
      "metadata": {
        "id": "dP6OJNdTwttr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# Evaluate each target separately\n",
        "target_names = ['Major', 'Faculty', 'Degree', 'Campus']\n",
        "for i, name in enumerate(target_names):\n",
        "    print(f\"\\n{name} Evaluation Report:\")\n",
        "    print(classification_report(y_test[:, i], y_pred[:, i], digits=4))\n",
        "\n",
        "    # If you want just the macro F1 (good for imbalanced classes):\n",
        "    f1 = f1_score(y_test[:, i], y_pred[:, i], average='macro')\n",
        "    print(f\"{name} Macro F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "aDoFVTUv83pV",
        "outputId": "704a36a2-3555-4fcb-80e9-d0d52f1c389f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Major Evaluation Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000         3\n",
            "           1     1.0000    0.7500    0.8571         4\n",
            "           2     1.0000    1.0000    1.0000         4\n",
            "           3     1.0000    1.0000    1.0000         4\n",
            "           4     1.0000    1.0000    1.0000         3\n",
            "           5     1.0000    1.0000    1.0000         4\n",
            "           6     1.0000    1.0000    1.0000         4\n",
            "           7     1.0000    1.0000    1.0000         4\n",
            "           8     1.0000    1.0000    1.0000         3\n",
            "           9     1.0000    1.0000    1.0000         3\n",
            "          10     0.8000    1.0000    0.8889         4\n",
            "          11     1.0000    0.7500    0.8571         4\n",
            "          12     1.0000    1.0000    1.0000         3\n",
            "          13     1.0000    0.7500    0.8571         4\n",
            "          14     1.0000    1.0000    1.0000         4\n",
            "          15     1.0000    1.0000    1.0000         3\n",
            "          16     1.0000    1.0000    1.0000         3\n",
            "          17     0.7500    1.0000    0.8571         3\n",
            "          18     1.0000    1.0000    1.0000         4\n",
            "          19     1.0000    1.0000    1.0000         4\n",
            "          20     1.0000    1.0000    1.0000         4\n",
            "          21     1.0000    1.0000    1.0000         4\n",
            "          22     0.8000    1.0000    0.8889         4\n",
            "          23     1.0000    1.0000    1.0000         4\n",
            "          24     1.0000    1.0000    1.0000         3\n",
            "          25     1.0000    1.0000    1.0000         3\n",
            "          26     1.0000    1.0000    1.0000         4\n",
            "          27     1.0000    1.0000    1.0000         4\n",
            "          28     0.7500    0.7500    0.7500         4\n",
            "          29     1.0000    1.0000    1.0000         3\n",
            "          30     0.6667    0.6667    0.6667         3\n",
            "          31     1.0000    1.0000    1.0000         4\n",
            "\n",
            "    accuracy                         0.9569       116\n",
            "   macro avg     0.9615    0.9583    0.9570       116\n",
            "weighted avg     0.9625    0.9569    0.9566       116\n",
            "\n",
            "Major Macro F1 Score: 0.9570\n",
            "\n",
            "Faculty Evaluation Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000         8\n",
            "           1     0.9375    1.0000    0.9677        15\n",
            "           2     0.9286    0.9286    0.9286        14\n",
            "           3     1.0000    1.0000    1.0000        10\n",
            "           4     1.0000    1.0000    1.0000         8\n",
            "           5     1.0000    1.0000    1.0000         4\n",
            "           6     1.0000    0.9375    0.9677        16\n",
            "           7     0.7500    1.0000    0.8571         3\n",
            "           8     1.0000    1.0000    1.0000         3\n",
            "           9     1.0000    0.7500    0.8571         4\n",
            "          10     1.0000    1.0000    1.0000        11\n",
            "          11     1.0000    1.0000    1.0000         4\n",
            "          12     1.0000    1.0000    1.0000         3\n",
            "          13     1.0000    1.0000    1.0000         7\n",
            "          14     1.0000    1.0000    1.0000         6\n",
            "\n",
            "    accuracy                         0.9741       116\n",
            "   macro avg     0.9744    0.9744    0.9719       116\n",
            "weighted avg     0.9768    0.9741    0.9741       116\n",
            "\n",
            "Faculty Macro F1 Score: 0.9719\n",
            "\n",
            "Degree Evaluation Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000         3\n",
            "           1     0.9130    0.9545    0.9333        22\n",
            "           2     0.9091    1.0000    0.9524        10\n",
            "           3     0.9333    1.0000    0.9655        14\n",
            "           4     1.0000    0.8378    0.9118        37\n",
            "           5     0.8000    1.0000    0.8889         8\n",
            "           6     0.7500    0.7500    0.7500         4\n",
            "           7     1.0000    1.0000    1.0000         8\n",
            "           8     0.8000    1.0000    0.8889         4\n",
            "           9     1.0000    1.0000    1.0000         3\n",
            "          10     1.0000    1.0000    1.0000         3\n",
            "\n",
            "    accuracy                         0.9310       116\n",
            "   macro avg     0.9187    0.9584    0.9355       116\n",
            "weighted avg     0.9383    0.9310    0.9308       116\n",
            "\n",
            "Degree Macro F1 Score: 0.9355\n",
            "\n",
            "Campus Evaluation Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8333    0.9375    0.8824        16\n",
            "           1     0.6364    1.0000    0.7778         7\n",
            "           2     0.8000    1.0000    0.8889         8\n",
            "           3     1.0000    1.0000    1.0000         7\n",
            "           4     1.0000    1.0000    1.0000         8\n",
            "           5     1.0000    1.0000    1.0000         3\n",
            "           6     1.0000    1.0000    1.0000         4\n",
            "           7     1.0000    0.8261    0.9048        46\n",
            "           8     1.0000    1.0000    1.0000         7\n",
            "           9     1.0000    1.0000    1.0000         7\n",
            "          10     1.0000    1.0000    1.0000         3\n",
            "\n",
            "    accuracy                         0.9224       116\n",
            "   macro avg     0.9336    0.9785    0.9503       116\n",
            "weighted avg     0.9413    0.9224    0.9249       116\n",
            "\n",
            "Campus Macro F1 Score: 0.9503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_major(user_data):\n",
        "    \"\"\"\n",
        "    Predict major based on user input\n",
        "    \"\"\"\n",
        "    # Load model and encoders\n",
        "    model = joblib.load('major_recommendation_model.pkl')\n",
        "    le_major = joblib.load('le_major.pkl')\n",
        "    le_faculty = joblib.load('le_faculty.pkl')\n",
        "    le_degree = joblib.load('le_degree.pkl')\n",
        "    le_campus = joblib.load('le_campus.pkl')\n",
        "\n",
        "    # Prepare user input\n",
        "    X_user, detected_info = prepare_user_input(user_data)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(X_user)\n",
        "\n",
        "    # Decode predictions\n",
        "    result = {\n",
        "        'major': le_major.inverse_transform([prediction[0][0]])[0],\n",
        "        'faculty': le_faculty.inverse_transform([prediction[0][1]])[0],\n",
        "        'degree': le_degree.inverse_transform([prediction[0][2]])[0],\n",
        "        'campus': le_campus.inverse_transform([prediction[0][3]])[0],\n",
        "        'detected_info': detected_info\n",
        "    }\n",
        "\n",
        "    # Get probabilities for top recommendations\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        probas = [estimator.predict_proba(X_user)[0] for estimator in model.estimators_]\n",
        "        major_probas = list(zip(le_major.classes_, probas[0]))\n",
        "        major_probas.sort(key=lambda x: x[1], reverse=True)\n",
        "        result['top_recommendations'] = major_probas[:3]  # Top 3 majors\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "dVG1uXTpSsMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example user input\n",
        "user_data = {\n",
        "    'riasec': {'R': 1, 'I': 1, 'A': 0, 'S': 0, 'E': 0, 'C': 1},\n",
        "    'skills_text': \"I know Python, Java, and some database management\",\n",
        "    'courses_text': \"AP Computer Science, web development bootcamp\",\n",
        "    'work_style': \"Office/Data\",\n",
        "    'passion_text': \"I love technology and building software\"\n",
        "}\n",
        "\n",
        "# Get prediction\n",
        "result = predict_major(user_data)\n",
        "print(\"Predicted Major:\", result['major'])\n",
        "print(\"Faculty:\", result['faculty'])\n",
        "print(\"Detected Skills:\", result['campus'])\n",
        "print(\"Detected Courses:\", result['degree'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaGw8DO4Syah",
        "outputId": "e79fab00-e923-46a6-98f5-7d58b258f249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Major: Computer Science\n",
            "Faculty: Faculty of Sciences\n",
            "Detected Skills: Distributed\n",
            "Detected Courses: BS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "788d9cad",
        "outputId": "babbf2cd-37b5-4323-c933-77e88d864bd0"
      },
      "source": [
        "%pip install fuzzywuzzy python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 fuzzywuzzy-0.18.0 python-Levenshtein-0.27.1 rapidfuzz-3.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create a models directory in Colab\n",
        "!mkdir -p models\n",
        "\n",
        "# Save all your models (add this after training)\n",
        "joblib.dump(model, 'models/major_recommendation_model.pkl')\n",
        "joblib.dump(mlb_skills, 'models/mlb_skills.pkl')\n",
        "joblib.dump(mlb_courses, 'models/mlb_courses.pkl')\n",
        "joblib.dump(ohe_work_style, 'models/ohe_work_style.pkl')\n",
        "joblib.dump(ohe_passion, 'models/ohe_passion.pkl')\n",
        "joblib.dump(le_major, 'models/le_major.pkl')\n",
        "joblib.dump(le_faculty, 'models/le_faculty.pkl')\n",
        "joblib.dump(le_degree, 'models/le_degree.pkl')\n",
        "joblib.dump(le_campus, 'models/le_campus.pkl')\n",
        "joblib.dump(list(all_skills), 'models/master_skills.pkl')\n",
        "joblib.dump(list(all_courses), 'models/master_courses.pkl')\n",
        "joblib.dump(list(all_passions), 'models/master_passions.pkl')\n",
        "joblib.dump(list(all_work_styles), 'models/master_work_styles.pkl')\n",
        "\n",
        "print(\"All models saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBZTXS2ybAsT",
        "outputId": "0b07b5a9-1e76-4927-ae43-7fa32f4d6772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a zip file of all models\n",
        "!zip -r models.zip models/\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('models.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "mRDDXTBpbKwT",
        "outputId": "2685bd7d-f2d1-4920-8961-9380c4a5a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/le_campus.pkl (deflated 38%)\n",
            "  adding: models/ohe_passion.pkl (deflated 48%)\n",
            "  adding: models/le_degree.pkl (deflated 33%)\n",
            "  adding: models/le_faculty.pkl (deflated 44%)\n",
            "  adding: models/mlb_skills.pkl (deflated 42%)\n",
            "  adding: models/master_skills.pkl (deflated 42%)\n",
            "  adding: models/master_courses.pkl (deflated 57%)\n",
            "  adding: models/master_passions.pkl (deflated 48%)\n",
            "  adding: models/mlb_courses.pkl (deflated 56%)\n",
            "  adding: models/ohe_work_style.pkl (deflated 55%)\n",
            "  adding: models/le_major.pkl (deflated 40%)\n",
            "  adding: models/master_work_styles.pkl (deflated 67%)\n",
            "  adding: models/major_recommendation_model.pkl (deflated 79%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_69198adb-ca8a-4f35-84be-e6b4fa92fc24\", \"models.zip\", 1570992)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}